''' This file is create by Yushu Huang
for joint DMBI project of Cindy Lam, Alaina Srivastav and Yushu Huang.
Last revision 08/28/2025. 
Purpose of this file: to prompt for factor -> outcome summarization. 

Input Data: chunks as document.pkl. 
Chained prompt engineering'''

# %%
import os
import re
import json

import openai
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_openai import ChatOpenAI

from chunking import chunking

class prompt():
    def __init__(self, chunked_docs, outcome_definition, api_key):
        self.chunked_docs       = chunked_docs
        self.outcome_definition = outcome_definition
        self.api_key            = api_key

    def _find_factors_to_result(self, phenomenon_definition, chunk):
        openai.api_key = os.getenv("OPENAI_API_KEY")
        messages = [
            {"role": "system", 
            "content": ("You are an assistant specialized in summarizing and identifying key factors within a given context. You don't have specific domain knowledge at all, "
            "but you excel at extracting relevant information from text.")},
            {"role": "user", "content": (
                f"You are provided with context from a study on digital mindfulness-based interventions in psychology. "
                f"Your task is to identify and describe factors that contribute to the following phenomenon: \n\n"
                f"{phenomenon_definition}\n\n"
                f"Here is the context:\n{chunk}\n\n"
                "Please identify all relevant factors from the context and explain, in one sentence each, how they contribute to the phenomenon. "
                "If no factors are evident, respond with 'There are no related factors in this chunk.'"
            )}
        ]
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=messages,
            max_tokens=1000,
            temperature=0
        )
        return response.choices[0].message['content'].strip()
    def _find_factor_relation(self):
        ''' a prompt TBD. input: list of factors. output: find in context their relation, if the context mentioned. '''
        pass

    def write_summaries_to_txt(self, textlist_to_write, output_file):
        '''text_to_write: a list of texts. Each entry is a text generated by analyze_chunk'''
        with open(output_file, 'w', encoding='utf-8') as outfile:
            for text in textlist_to_write:
                outfile.write(text + "\n\n")
        print("Analyze results saved to text file. ")

    def generate_summary_files(self): 
        outcome_definition  = self.outcome_definition
        chunks              = self.chunked_docs
        for index, item in enumerate(outcome_definition, start=1):
            term        = item['phenomenon']
            definition  = item['definition']
            print(f"Start processing {item['phenomenon']} related causes")
            result = []
            output_file = term + '.txt'
            for chunk in chunks:
                result.append(self._find_factors_to_result(definition, chunk))
            print(f"Start saving {item['phenomenon']} related causes")
            self.write_summaries_to_txt(result, output_file)
            print(f"End saving {item['phenomenon']} related causes")
            # TODO: Make it more robust by removing summary list, but saving them chunk by chunk. 
        print("Done with generating summary files")



    

if __name__ == "__main__":
    path = os.getcwd()
    chunk_subpath = 'chunks'
    chunk_folder = os.path.join(path, chunk_subpath)
    chunk = chunking(chunk_folder)
    documents = chunk.load_chunks()
    
    outcome_filename = 'outcome_definition.json'
    with open(os.path.join(path, outcome_filename)) as outcome_file:
        outcome_definition = json.load(outcome_file)

    generate_prompt = prompt(chunked_docs = documents, outcome_definition = outcome_definition)
    generate_prompt.generate_summary_files()

   

