Contents lists available at ScienceDirect
Journal of Affective Disorders
journal homepage: www.elsevier.com/locate/jad
The efficacy of mindfulness meditation apps in enhancing users’ well-being
and mental health related outcomes: a meta-analysis of randomizedcontrolled trials
Éva Gála,⁎, Simona Ștefanb,c, Ioana A.
meta-analysis of randomizedcontrolled trials
Éva Gála,⁎, Simona Ștefanb,c, Ioana A. Cristead
aEvidenceBasedPsychologicalAssessmentandInterventionsDoctoralSchool,Babeș-BolyaiUniversity,Cluj-Napoca,Romania
bDepartmentofClinicalPsychologyandPsychotherapy,Babeș-BolyaiUniversity,Cluj-Napoca,Romania
cTheInternationalInstitutefortheAdvancedStudiesofPsychotherapyandAppliedMentalHealth,Babeș-BolyaiUniversity,Cluj-Napoca,Romania
dDepartmentofBrainandBehavioralSciences,UniversityofPavia,Pavia,Italy
ARTICLE
INFO
Keywords:
mindfulnessapp
randomized trial
well-beingmental-health
mHealthABSTRACT
Background: Mindfulness applications are popular tools for improving well-being, but their effectiveness is
unclear. We conducted a meta-analysis of randomized controlled trials (RCTs) that employed a mindfulness
meditation app as the main intervention to improve users’ well-being and mental-health related outcomes.
Methods: A systematic search was conducted in PsycINFO, PubMed, Web of Science, ProQuest
outcomes.
Methods: A systematic search was conducted in PsycINFO, PubMed, Web of Science, ProQuest Dissertations and
Theses Global, the Cochrane Library, Open Grey and ResearchGate through June, 2020. Effects were calculated
as standardized mean difference (Hedges’ g) between app-delivered mindfulness interventions and control
conditions at post-test and pooled with a random-effects model.
Results: From 2637 records, we selected 34 trials (N = 7566). Significant effect sizes were found at
From 2637 records, we selected 34 trials (N = 7566). Significant effect sizes were found at post-test for
perceived stress (n = 15; g= 0.46, 95% CI [0.24, .68], I2=68%), anxiety (n = 15; g= 0.28, 95% CI [0.16,
.40],I2=35%), depression (n = 15; g= 0.33, 95% CI [0.24, .43], I2=0%), and psychological well-being
(n = 5;g= 0.29, 95% CI [0.14, .45], I2=0%). No significant effects were found for distress at post-test (n = 6;
g= 0.10, 95% CI [-0.02, .22], I2=11%) and general well-being (n = 5; g= 0.14,
at post-test (n = 6;
g= 0.10, 95% CI [-0.02, .22], I2=11%) and general well-being (n = 5; g= 0.14, 95% CI [-0.02, 0.29],
I2= 14%).
Conclusionandlimitations: Mindfulness apps seem promising in improving well-being and mental-health, though
results should be interpreted carefully due to the small number of included studies, overall uncertain risk of biasand heterogeneity.
1. Introduction
Mindfulness was introduced to the western psychological world by
Jon Kabat- Zinn, who tried to secularize
was introduced to the western psychological world by
Jon Kabat- Zinn, who tried to secularize methods from Buddhist prac-
tice (Tirch et al., 2015) and developed his Mindfulness- Based Stress
Reduction (MBSR) program. The program rapidly became popular, and
mindfulness expanded at large-scale (Reibel & McCrown, 2019).
Briefly, mindfulness refers to the non-judgmental awareness of the
present moment, by observing and accepting our unfolding experiences,
emotions, thoughts and physical sensations
by observing and accepting our unfolding experiences,
emotions, thoughts and physical sensations (Kabat-Zinn, 2003). Mind-
fulness is conceptualized as a skill that can be improved through formal
meditation (e.g., focused attention, awareness of breathing, emotions or
thoughts) and informal practices (e.g., open monitoring of experiences,
cultivating awareness during regular daily activities, like walking;Mace, 2007; Plaza et al., 2013; Wahbeh & Oken, 2016).
Growing evidence supports the
like walking;Mace, 2007; Plaza et al., 2013; Wahbeh & Oken, 2016).
Growing evidence supports the beneficial effects of mindfulness
training for clinical and non-clinical populations. Several meta-analysesshowed the effectiveness of mindfulness-based interventions (MBIs) in
the treatment of somatization disorder (Lakhan & Schoefield, 2013),
anxiety (Vollestad et al., 2012), depression (Cavanagh et al., 2014),
including relapse prevention (Kuyken et al., 2016). Practicing mind-
fulness meditation
al., 2014),
including relapse prevention (Kuyken et al., 2016). Practicing mind-
fulness meditation was also associated with enhanced well-being in
healthy individuals (Keng et al., 2011; Lomas et al., 2018).
Digital delivery is gaining traction as a way of increasing the ac-
cessibility of psychological treatments (Fairburn & Patel, 2017). MBIs
have already been successfully adapted to the online context, several
meta-analyses confirming that online MBIs are effective
(Jaywardene et al., 2017;
context, several
meta-analyses confirming that online MBIs are effective
(Jaywardene et al., 2017; Spijkerman et al., 2016). Moreover,
https://doi.org/10.1016/j.jad.2020.09.134
Received 30 March 2020; Received in revised form 30 July 2020; Accepted 27 September 2020⁎Corresponding author: Éva Gál, Evidence Based Psychological Assessment and Interventions Doctoral School, Babeș- Bolyai University, Republicii Street 37,
400015, Cluj-Napoca, Romania. Tel.: 00 40 744 863 375.
E-mailaddresses:
Republicii Street 37,
400015, Cluj-Napoca, Romania. Tel.: 00 40 744 863 375.
E-mailaddresses: ge.evagal@gmail.com, gal.eva@ubbonline.ubbcluj.ro (É. Gál).Journal of Affective Disorders 279 (2021) 131–142
Available online 07 October 2020
0165-0327/ © 2020 Elsevier B.V. All rights reserved.
T individual RTCs have found comparable effects to face-to-face inter-
ventions (Compen et al., 2018) and demonstrated that an online
mindfulness course significantly reduced stress and these gains re-
mained
that an online
mindfulness course significantly reduced stress and these gains re-
mained stable at follow-up (Krusche et al., 2012). Mobile technology
provides a further platform for delivering mindfulness interventions
(Garcia et al., 2017), but evidence of effectiveness has been mixed. Two
recent meta-analyses on app-supported smartphone interventions for
mental health problems found that these outperformed the control
conditions for outcomes of distress, quality of life, symptoms of
these outperformed the control
conditions for outcomes of distress, quality of life, symptoms of de-
pression and anxiety (Linardon et al., 2019). However, app-delivered
interventions conferred no additional benefits for negative affect, panic
and post-traumatic stress disorder symptoms (Linardon et al., 2019).
Mindfulness meditation apps are one of the most common in the
mental health and well-being app category (Coulon et al., 2016;
Pospos et al., 2018), totaling over 260 apps (Mani et al.,
app category (Coulon et al., 2016;
Pospos et al., 2018), totaling over 260 apps (Mani et al., 2015). Public
interest in mindfulness practice is high: around 10% of the individuals
included in the National Health Survey between 2002 and 2012 re-
ported practicing mindfulness to improve their health and well-being
(Clarke et al., 2015). The number is probably an underestimation, since
many more individuals are resorting to mobile apps. According to
company reports in 2018, Headspace has over 1
individuals are resorting to mobile apps. According to
company reports in 2018, Headspace has over 1 million paid sub-
scribers (Pesce, 2018), while Calm reached over 80 million downloads.
Yet the app marketplace is generally characterized by high availability
and low evidence base (Leigh & Flatt, 2015), often promoting strategies
and exercises lacking evidence or developed without clinical expertise
(Coulon et al., 2016; Nicholas et al., 2015; Sucala et al., 2017). Fur-
thermore, providing
et al., 2016; Nicholas et al., 2015; Sucala et al., 2017). Fur-
thermore, providing incorrect information and dishonest advertising isalso a common phenomenon (Coulon et al., 2016; Nicholas et al.,
2015).
The feasibility of mindfulness training apps has been examined in
several populations like employees (Muuraiskangas et al., 2016), stu-
dents (Donovan et al., 2016) and cancer patients (Mikolasek et al.,
2018). Participants generally perceived the apps as useful tools forenhancing well-being.
et al.,
2018). Participants generally perceived the apps as useful tools forenhancing well-being. Several randomized controlled trials (RCT)
showed a range of benefits for mindfulness meditation apps. Mind-
fulness meditation apps were found to be efficient in reducing anxiety,
depression, fear of recurrence (Lengacher et al., 2018) and distress
(Kubo et al., 2019) among cancer patients and compassion fatigue and
burnout among hospice and palliative care professionals (Heeter et al.,
2017). RCTs
fatigue and
burnout among hospice and palliative care professionals (Heeter et al.,
2017). RCTs using a mindfulness meditation app as the intervention
demonstrated significant improvements on well-being, distress
(Bostock et al., 2019), life satisfaction (Champion et al., 2018), stress
(Smith et al., 2020) depressive (Flett et al., 2019; Fish and Saul, 2019)
and anxiety symptoms (van Emmerik et al., 2018). Furthermore, the useof mindfulness meditations apps was shown to exert positive effects
al., 2018). Furthermore, the useof mindfulness meditations apps was shown to exert positive effects on
quality of life in unselected sample (Economides et al., 2018; Mak et al.,
2018; Yang et al., 2018) or among women diagnosed with breast cancer
(Rosen et al., 2018). Studies also showed that improvements in mental
health are maintained at 4 (Flett et al., 2019) and 16 weeks
(Bostock et al., 2019) after the intervention.
Mobile app-based mindfulness interventions demonstrated similar
effects
after the intervention.
Mobile app-based mindfulness interventions demonstrated similar
effects compared to a therapist-led mindfulness group, and performed
better than an educational program in terms of reductions in symptoms
of depression and anxiety (Cox et al., 2019). Furthermore, app-deliv-
ered mindfulness interventions showed comparable effects with app-
delivered self-compassion and cognitive-behavioral psychoeducation in
improving well-being and reducing distress (Mak et al., 2018).
psychoeducation in
improving well-being and reducing distress (Mak et al., 2018). How-
ever, when compared to sham meditation, although, a significant in-
crease from pre to post-test in positive and negative affect could be
observed, they were not attributable to mindfulness practice since the
sham meditation group reported similar improvements (Noone and
Hogan, 2018). Several studies yielded mixed results, reporting sig-
nificant improvements in positive affect (Howells et al., 2016; Lee
mixed results, reporting sig-
nificant improvements in positive affect (Howells et al., 2016; Lee and
Jung, 2018) and mindfulness (Wen et al., 2017), while no differenceswere found regarding negative affect (Howells et al., 2016; Wen et al.,
2017), life satisfaction (Howells et al., 2016), stress, state anxiety,physical and social functioning (Lee and Jung, 2018). Despite the ac-cumulation of trials, systematic reviews and meta-analyses of mind-
fulness apps for mental health and well-being
trials, systematic reviews and meta-analyses of mind-
fulness apps for mental health and well-being outcomes are lacking.
AsFirth et al. (2017a) have stated, the accessibility of mHealth apps
and their large media promotion have created a “duty of care” situa-
tion, when informing the public about their usefulness and evidence-
base is crucial. Hence, the present meta-analysis, proposes to integrate
available research on the effectiveness of mindfulness meditation apps
in improving users’
integrate
available research on the effectiveness of mindfulness meditation apps
in improving users’ well-being and mental health related outcomes
(e.g., symptoms of anxiety and depression, perceives stress, psycholo-
gical well-being, life satisfaction, quality of life, positive and negative
emotions).
2. Method
The protocol of this systematic review was registered (PROSPERO
registration: CRD42019132276). Changes to the protocol are described
in the corresponding sections and in the
CRD42019132276). Changes to the protocol are described
in the corresponding sections and in the Supplementary Materials. The
PRISMA guidelines (Moher et al., 2009) were followed for reporting.
2.1. Identificationandselectionofstudies
A systematic literature search was conducted in the following
electronic databases: PubMed, Web of Science, PsycINFO, ProQuest
Dissertations and Theses Global, Cochrane Library from inception until
June 10
th2020, using combinations of the following keywords:
Cochrane Library from inception until
June 10
th2020, using combinations of the following keywords: mind-
fulness, mindfulness meditation, mindful meditation, intervention,
trial, RCT, randomized, randomized, randomized controlled trial,
training, effect, impact, app, application, mobile, phone, smartphone,
app-delivered, mhealth, m-health, mobile-based, mobile-health, well-
being, wellbeing, satisfaction, emotion, affect, quality, mental health,
stress, distress, depression, anxiety (see
satisfaction, emotion, affect, quality, mental health,
stress, distress, depression, anxiety (see Supplementary Materials for
the complete search strings). To identify unpublished studies, besides
including theses and dissertations, we also searched two databases (i.e.,
Open Grey and ResearchGate with mindful* app* as keywords – these
sites does not allow for long search strings), which contain conference
papers, preprints and unpublished manuscripts as well. Since
ResearchGate does not allow
conference
papers, preprints and unpublished manuscripts as well. Since
ResearchGate does not allow for reference exporting, only the first 200
hits were examined for eligibility. When full-text papers were not
available (n=5) a request was sent to the authors (no positive response
were obtained). A legacy search was also conducted by reviewing the
reference list of the included studies and meta-analyses on mindfulness
interventions to identify potential studies. Furthermore, the homepages
of
on mindfulness
interventions to identify potential studies. Furthermore, the homepages
of the two most popular mindfulness apps (i.e., Headspace and Calm)
was also hand-searched.
Eligible studies were RCTs comparing an app for mindfulness
meditation/training to a control condition (e.g., waitlist, attention
control) or an active psychological treatment (e.g., existing interven-
tions, techniques used to increase well-being or mental health) for
outcomes related to well-being and mental health.
used to increase well-being or mental health) for
outcomes related to well-being and mental health. Mental health out-
comes included symptoms of anxiety and depression, burnout, and
stress. For well-being, we adopted a broad definition so as to capture its
multidimensional nature (Diener, 2000; Khaneman et al. 1999, Ryff &
Keyes, 1995), in line with previous meta-analyses (e.g., Lomas et al.,
2018). Indicators of eudaimonic (e.g., flourishing, psychological well-
being) and hedonic (e.g.,
Indicators of eudaimonic (e.g., flourishing, psychological well-
being) and hedonic (e.g., positive and negative affect, life satisfaction)
were also included. However, state measures of affective states were
excluded as they might index only transient variations.
Eligible mindfulness apps could feature different types of meditation
and any mindfulness exercises (e.g., guided meditations, breathingawareness, body scan). Studies were included if app-guided mind-
fulness practice was the main
body scan). Studies were included if app-guided mind-
fulness practice was the main component of the intervention. Studies
where mindfulness was an element of a more complex intervention or
as adjunctive to a face-to-face one were excluded, as were studies ex-
amining one-time (i.e. single session) use of the mindfulness app.É.Gál,etal. Journal of Affective Disorders 279 (2021) 131–142
132 2.2. Dataextraction
For each included study, the following data were extracted: first
author, year of
Dataextraction
For each included study, the following data were extracted: first
author, year of publication, population (type of sample, mean age,
gender distribution, number of participants in each condition, number
of drop-outs), intervention (app, whether it was commercially available
or developed by the researchers as part of the trial), frequency of in-
structed use, intervention duration (weeks), session length (minutes),
average number of completed sessions, contact with the researchers
session length (minutes),
average number of completed sessions, contact with the researchers (no
or minimal contact), number of reminders sent to complete mindfulness
sessions, type of control condition), outcome (means and standard de-
viations if available).
Outcomes enclosed a range of mental health and well-being related
outcomes assessed at post-test and follow-up (e.g., symptoms of anxiety
and depression perceives stress, general and psychological well-being,
life satisfaction, quality of
depression perceives stress, general and psychological well-being,
life satisfaction, quality of life, positive and negative emotions, burnout,
distress). Baseline and post-intervention mindfulness scores were also
extracted as secondary outcomes. For studies reporting both intent-to-
treat (ITT) and per-protocol analysis, both were extracted.
2.3. Riskofbiasassessment
Risk of bias was assessed independently by two of the authors (EG,
SS) using the Cochrane Collaboration's Risk of Bias (RoB)
independently by two of the authors (EG,
SS) using the Cochrane Collaboration's Risk of Bias (RoB) assessment
tool (Higgins & Green 2011). The following six domains were rated:
random sequence generation, allocation concealment, blinding of par-
ticipants and personnel, blinding of outcome assessment, incomplete
outcome data, and selective outcome reporting. Each domain was
ranked as low, high or uncertain for risk of bias. Selection bias was
rated as low risk if there was a random component in
uncertain for risk of bias. Selection bias was
rated as low risk if there was a random component in the allocation
sequence generation, while allocation concealment was considered to
be a low risk when a clear method that prevented foreseeing group
allocation before or during enrollment was described. Blinding of par-
ticipants was rated as low when a study incorporated an attention
control condition or the app-delivered intervention was compared with
an active psychological treatment, and
condition or the app-delivered intervention was compared with
an active psychological treatment, and consequently, participants could
not be sure whether they are in the intervention or control condition.
Blinding of outcome assessors was rated as low risk if proper measures
were taken to conceal participants’ group membership, or if the out-
come measures were self-reported, which did not involve a direct in-
teraction with the assessor. The risk for attrition bias was regarded as
low, if all
a direct in-
teraction with the assessor. The risk for attrition bias was regarded as
low, if all randomized participants were included in the analysis (i.e.,
intent-to-treat analysis or complete data). Selective reporting was
evaluated as low risk if all the prespecified outcomes in the trial pro-
tocol (identified by trial registration numbers) were reported. When
trial protocol was not available, selective reporting was rated as unclear
of risk of bias. For each criterion inter-rater
available, selective reporting was rated as unclear
of risk of bias. For each criterion inter-rater agreement was assessed
prior to resolving disagreements using the Cohen's kappa coefficient.
For each study an overall RoB score was also computed by assigning 1
point for each domain evaluated as having low risk and was used as an
indicator of study quality (higher scores indicating lower risk of bias). A
sensitivity analysis was performed by excluding studies with a RoB
score of 4 or lower.
2.4.
A
sensitivity analysis was performed by excluding studies with a RoB
score of 4 or lower.
2.4. Statisticalanalysis
All analyses were conducted using Comprehensive Meta-Analysis
(CMA version 2.2), forest plots were generated using the metan com-
mand in STATA (STATA Corp., Inc., College Station, TX).
Between -group standardized mean difference (SMD) were calcu-
lated based on post-test means, standard deviations (SDs), and samplesize. SMD represents the difference in means between the
means, standard deviations (SDs), and samplesize. SMD represents the difference in means between the intervention
and control arms divided by the pooled standard deviation
(Borenstein et al., 2011). When these were not reported, we computed
the SMD from alternative statistics (Borenstein et al., 2011), such as tor
pvalues from independent group comparisons. We used Hedges’ gas astandard metric of the effect size, which includes an adjustment for
small sample studies. The interpretation is
of the effect size, which includes an adjustment for
small sample studies. The interpretation is similar to Cohen's d: 0.2
represents small, 0.5 medium, while 0.8 large effect sizes
(Cohen, 2013). Prediction intervals (it estimates where the true effects
of 95% of future similar studies are to be expected) were also calculated
(InHout et al., 2016).
Though initially we planned to also report within (i.e., pre-post)
group effects, this analysis was omitted due to methodological con-
siderations.
(i.e., pre-post)
group effects, this analysis was omitted due to methodological con-
siderations. As Cuijpers et al., (2016) point out pre- and post-test scores
are not independent and the correlation is generally not reported.Furthermore, change from pre- to post-test can also be influenced by
factors unrelated to the intervention (e.g., natural course of the dis-
order, participant expectations). As suggested by the Cochrane Hand-
book (Higgins & Green, 2011, sec. 9.1.4), separate analyses
As suggested by the Cochrane Hand-
book (Higgins & Green, 2011, sec. 9.1.4), separate analyses were car-
ried out for the different mental-health and well-being outcomes if
three or more trials have reported those outcomes.
When studies included multiple subgroups, they were combined to
create a single pair-wise comparison (Borenstein et al., 2011). Intent-to-
treat (ITT) analyses were preferred over per protocol (PP), where
available. A sensitivity analysis by excluding studies with ITT
over per protocol (PP), where
available. A sensitivity analysis by excluding studies with ITT analysis
was performed to explore possible differences between studies re-
porting ITT and PP analyses.
Since there was a considerable diversity in the interventions and
population characteristics, a random-effects model was used in all
analyses, which assumes that differences between study effect sizes are
not only due to random error, but also to real variation in the inter-
vention effect (Hedges &
are
not only due to random error, but also to real variation in the inter-
vention effect (Hedges & Vevea, 1998). A study was considered to be an
outlier when its 95% confidence interval (CI) was outside of the 95% CI
of the pooled effect (Cuijipers, 2016). Heterogeneity was examined
using theI
2statistics which determines the percentage of the total
variation across studies due to heterogeneity: 0% indicating no, 25%low, 50% moderate, and 70% high heterogeneity (Borenstein et al.,
2011).
0% indicating no, 25%low, 50% moderate, and 70% high heterogeneity (Borenstein et al.,
2011). Confidence intervals for the I
2statistics were computed fol-
lowing the large-sample approximation-based method presented by
Borenstein et al. (2009).
2.5. Subgroup,sensitivityandmeta-regressionanalyses
In the protocol, we had planned a range of subgroup and meta-re-
gression analyses for type of control, commercially available apps
versus those developed as part of the trial, type of well-being
control, commercially available apps
versus those developed as part of the trial, type of well-being indicator,
length of the intervention, frequency of meditation sessions, change in
mindfulness from pre- to post-test, average completed session.
However, considering the rule of at least 10 studies per characteristics
modeled (Higgins & Green, 2011, sec. 9.6.5.1) no such analyses were
carried out because none of the outcomes passed this threshold. To test
the robustness of the results, we
out because none of the outcomes passed this threshold. To test
the robustness of the results, we employed several sensitivity analyses
(when there were multiple studies available for an outcome): (i) type of
control condition (i.e., attention, waitlist or active psychological
treatment), (ii) whether participants had minimal or no contact with
the researchers, (iii) excluding outliers, (iv) considering only studies
using Headspace, (v) and for studies reporting PP analysis.
2.6.
(iv) considering only studies
using Headspace, (v) and for studies reporting PP analysis.
2.6. Smallstudyeffects
Small study effects, a potential indicator of publication bias was
examined by visually inspecting the funnel plot and by Egger's test of
the intercept for outcomes where at least ten studies were available
(Egger et al., 1997; Higgins & Green, 2011, sec. 10.4.3.1). The protocol
included additional analyses for detecting publication bias (i.e., Ro-senthal's fail-safe N, the trim and
additional analyses for detecting publication bias (i.e., Ro-senthal's fail-safe N, the trim and fill procedure), but due to their
methodological weaknesses and unreliability of their estimates (Higgins
& Green, 2011, sec.10.4.4.2 and sec. 10.4.4.3), these were not carried
out.É.Gál,etal. Journal of Affective Disorders 279 (2021) 131–142
133 3. Results
3.1. Identificationandselectionofstudies
The initial search yielded 2637 records, (1680 after removing du-
plicates). A further 1601 records were
initial search yielded 2637 records, (1680 after removing du-
plicates). A further 1601 records were removed following title and
abstract screening. Seventy-nine full-texts were retrieved and examinedfor eligibility, out of which 45 were excluded, leaving 34 included
RCTs. A PRISMA flow diagram of the study selection process is shown
inFigure 1.
3.2. Studycharacteristics
Characteristics of the included studies are presented in Table 1. The
34 RCTs included 7,612 participants, from which 3,260
included studies are presented in Table 1. The
34 RCTs included 7,612 participants, from which 3,260 received a
mindfulness app, and 4,352 a control intervention. Study sample sizes
were highly variable ranging from 12 to 2,283. Studies included diverse
samples: unselected sample (n = 3,270), employees (n = 600), stu-
dents (n = 1,436), adults with elevated symptoms of depression or
anxiety (n = 500) and signs of compulsive internet use (n=994),
women approaching childbirth (n = 78), foster
= 500) and signs of compulsive internet use (n=994),
women approaching childbirth (n = 78), foster parents (n = 150),
intensive care unit patients (n = 80), or women diagnosed with breast
cancer (n = 240), chronic pelvic pain (n = 90) or myeloproliferative
neoplasm (n = 128). Women accounted for 64% of all participants and
mean ages ranged from 17 to 58 years.
The majority of the studies included only one control condition
(n = 27). A few studies which had two control conditions (both
included only one control condition
(n = 27). A few studies which had two control conditions (both wait-
list/attention and active psychological treatment; n = 4) or used two
mindfulness apps (n = 3). Most trials used waitlist (n = 21), or at-
tention (n = 9) control conditions (e.g., note taking, cognitive training
game, sham meditation). Seven RCTs used active psychologicaltreatments as comparators (e.g., self-compassion or telephone-basedmindfulness training). Only 9 studies included a
(e.g., self-compassion or telephone-basedmindfulness training). Only 9 studies included a follow-up assessment,
5 comparing a mindfulness app with a waitlist or attention control
condition, and 4 with an active psychological treatment. Most studies
(n = 29) used a commercially available app, whereas the remaining
ones (n = 5) developed the app as part of the study. Overall, 13 distinct
commercially available apps were used (see Table 1), with the most
common ones being Headspace (n = 16) and
available apps were used (see Table 1), with the most
common ones being Headspace (n = 16) and Calm (n = 4).
Interventions lasted between 10 days and 8 weeks and in most cases
(n = 17) participants were advised to use the app once a day. Follow-
up period ranged between 1 and 24 weeks, the most common being a
12-week follow-up period. Across the included studies, session duration
ranged from 3 to 37 minutes, with the most frequent session duration
being 10 minutes. Participants had no contact
to 37 minutes, with the most frequent session duration
being 10 minutes. Participants had no contact with the researchers in
17 trials, and had one introductory in-person session or call in 14 (3
studies did not mention this aspect). On average, participants com-
pleted around 43% of the recommended sessions. Detailed information
about the content of the mindfulness applications and the type of
control conditions are presented in Table S1 in Supplementary
Materials.
3.3. Outcomemeasures
The most
conditions are presented in Table S1 in Supplementary
Materials.
3.3. Outcomemeasures
The most frequently assessed mental health and well-being related
outcomes were symptoms of depression (n = 15) and anxiety (n = 15),
perceived stress (n= 15), psychological and general well-being (n = 9),
life satisfaction (n = 4), quality of life (n = 5). Eleven studies also
measured mindfulness skills. A complete list of the instruments for well-
being indicators is presented in the Supplementary Materials
list of the instruments for well-
being indicators is presented in the Supplementary Materials (Table
S2). Outcomes measured at follow-up varied considerably, the most
common being stress (n = 6), anxiety (n = 4), depression (n = 3), and
Figure 1. PRISMA flow chart of study selection.É.Gál,etal. Journal of Affective Disorders 279 (2021) 131–142
134 Table 1
Characteristics of the included studies
Study N N of
drop-
outMean age Population characteristics Mindfulness
applicationControl condition
N N of
drop-
outMean age Population characteristics Mindfulness
applicationControl condition Length of the
interventionFollow-uptimeAdvisedfrequency of appuse/weekAveragecompletedsessionsIndicators of WB Type of
analysis
Abbott (2018) 163 - 24 Students (elevated worry) Headspace Waitlist 4 weeks - 7-14 - anxiety, worry ITT
Bhayee et al. (2016) 26 10 32.65 General population Muse, Calm Math training 6 weeks - 5 - anxiety,depression, QOLPP
Borjalilu et al. (2019) 68 - 24.29 Students Aramgar MBSR 3
6 weeks - 5 - anxiety,depression, QOLPP
Borjalilu et al. (2019) 68 - 24.29 Students Aramgar MBSR 3 weeks - - - stress, anxiety,depression-
Bostock et al. (2019) 238 9 35.5 Employee Headspace Waitlist 8 weeks 16 weeks 7 16.6 PWB, depression,anxietyPP
Carissoli et al. (2015) 56 0 38.1 Employee Developed Relaxing music 3 weeks - 14 16.8 stress PP
Carissoli et al. (2017) 78 - 33.2 Pregnant women Developed Childbirth class 4 weeks - 5 11.9 PWB -
Champion et al. (2018) 62 12 39.13 General population
Childbirth class 4 weeks - 5 11.9 PWB -
Champion et al. (2018) 62 12 39.13 General population Headspace Waitlist 4 weeks - 7 8.93 SWL, stress, PWB ITT, PP
Cox et al. (2019) 80 14 49.5 ICU patients Developed Mindfulness;
Education*4 weeks 12 weeks 1 3.87 QOL, anxiety,depression, distressITT
Economides et al. (2018) 69 19 30 General population Headspace Audiobook 2 weeks - 5 10 stress, PA, NA,
irritabilityPP
Fish & Saul (2019) 91 19 21 Students Headspace Waitlist 2 weeks 5 - depression PP
Flett et
& Saul (2019) 91 19 21 Students Headspace Waitlist 2 weeks 5 - depression PP
Flett et al. (2019) 208 16 20.8 Students Headspace
SmilingMindEvernote app 10 day - 7 8 stress, depression,anxiety, flourishingPP
Flett et al., (2020) 250 55 17.87 Students Headspace Waitlist 12 weeks - - - distress ITT
Forbes et al. (2020) 90 25 35.1 Women with chronic pelvic
painHeadspace Muscle relaxation;
Waitlist control8.5 weeks 24 weeks - - QOL, depression,
anxietyITT
Howells et al. (2016) 194 73 40.7 General
control8.5 weeks 24 weeks - - QOL, depression,
anxietyITT
Howells et al. (2016) 194 73 40.7 General population Headspace Catch Notes app 10 days - 7 - PA, NA,
depression, SWL,
flourishingPP
Huberty et al. (2019a) 109 21 20.4 Students Calm Waitlist 8 weeks 12 weeks 7 3.8 stress PP
Huberty et al. (2019b) 128 34 58 Patients with
myeloproliferative neoplasm10% HappierCalmEducationalcontrol4 weeks - 7 - depression, anxiety -
Kubo et al. (2019) 128 30 57.9 Cancer patients Headspace Waitlist 8 weeks -
- depression, anxiety -
Kubo et al. (2019) 128 30 57.9 Cancer patients Headspace Waitlist 8 weeks - 7 - distress, QOL,anxiety, depression
Lanz et al. (2019) 105 23 - General population Smiling Mind Waitlist 8 weeks - 5 35 burnout -
Lee & Jung. (2018) 206 41 20.6 Students DeStressify Waitlist 4 weeks - 5 - WB, anxiety,depressionPP
Levin et al. (2020) 23 7 20.4 Students Stop Breathe &
ThinkWaitlist 4 weeks - 7 7.44 anxiety,depression,
distress, WBPP
Loree (2018) 27 110 - Foster parents Calm
4 weeks - 7 7.44 anxiety,depression,
distress, WBPP
Loree (2018) 27 110 - Foster parents Calm Thought Diary 1 week 1 week 1 stress PP
Mak et al. (2018) 2282 1653 33.6 General population Developed Self-compassion;
CBT psychoed.4 weeks 12 weeks 7 9 WB, distress ITT, PP
Moberg et al. (2019) 500 296 30.2 Adults with elevated
symptoms of depression and
anxietyPacifica Waitlist 4 weeks 8 weeks - 19 depression,
depressionITT
Möltner et al. (2018) 306 - 42.8 Employees 7mind Waitlist 2 weeks - - -
19 depression,
depressionITT
Möltner et al. (2018) 306 - 42.8 Employees 7mind Waitlist 2 weeks - - - burnout, SWL -
Nolan (2019) 95 29 21 Students Headspace Waitlist 10 days - 7 6 stress, SWL,depression,anxiety, stressPP
Noone & Hogan (2018) 91 20 20.5 Students Headspace Sham meditation 6 weeks - 5 15 WB, PA, NA ITT
Quinones & Griffiths (2019) 994 631 40 Individuals with sign of
compulsive internet useHeadspace Arousal
decentering;Waitlist2 weeks - - - depression PP
Robinson (2018) 12 - 35
useHeadspace Arousal
decentering;Waitlist2 weeks - - - depression PP
Robinson (2018) 12 - 35 General population Headspace Waitlist 4 weeks 4 weeks 7 - stress, PA, NA,burnoutPP
Rosen et al. (2018) 112 48 52.3 Cancer patients Headspace Waitlist 8 weeks 4 weeks 7 18 QOL ITT
Siembor (2017) 21 3 20.89 Students Mindfulness App Waitlist 4 weeks - 7 - stress PP
(continuedonnextpage)É.Gál,etal. Journal of Affective Disorders 279 (2021) 131–142
135 quality of life (n = 3).
3.4. Attrition
All but five
of Affective Disorders 279 (2021) 131–142
135 quality of life (n = 3).
3.4. Attrition
All but five studies (Abbott, 2018; Borjalilu et al., 2019;
Carissoli et al., 2017; Möltner et al., 2018; Robinson, 2018) reported
the number of drop-outs (mean = 31.56%; range 0%- 73.3%). Drop-out
rates were slightly higher in the mindfulness meditation groups
(mean = 42%; range 0%- 77%) than in the control conditions
(mean = 34%; range 0% -79%). Drop-out rates largely driven by the
largest study (Mak et al.,
= 34%; range 0% -79%). Drop-out rates largely driven by the
largest study (Mak et al., 2018), where, from the total 2,283 rando-
mized participants, only 24% completed the study.
3.5. Riskofbias
According to the Cochrane Risk of Bias assessment, 8 studies (23%)
had low RoB in five domains and four studies (11%) were rated as low
risk in all six domains. Ten RCTs had high or unclear RoB in 2 domains,
while 7 studies in 3 and another 5 in 4 domains. Studies generally
provided little information
7 studies in 3 and another 5 in 4 domains. Studies generally
provided little information regarding the process of randomization
(n = 12) and allocation concealment (n = 20). All studies used self-
report scales for outcome assessment, thus were rated as low RoB.
Fifteen studies explicitly mentioned lack of blinding procedures of
participants and personnel and another five were rated unclear in this
domain due to lack of information. Eleven studies reported ITT analysis
and for 5 studies it was
due to lack of information. Eleven studies reported ITT analysis
and for 5 studies it was unclear whether all participants were included
in the analyses. Five studies were rated as unclear of RoB in selective
reporting due to the lack of pre-specified analytical method or in-
sufficient information (e.g., reducing subscales into factors). Inter-rater
agreement, based on the detailed risk of bias evaluation of the two
authors, was substantial for random sequence generation (Cohen's
kappa = .86),
evaluation of the two
authors, was substantial for random sequence generation (Cohen's
kappa = .86), allocation concealment (Cohen's kappa = .67), blinding
of participants and personnel (Cohen's kappa = .89), blinding of out-
come assessment (Cohen's kappa = .96), incomplete outcome data and
selective reporting (Cohen's kappa = .98). Figure 2 provides the gen-
eral risk of bias, while for each study's detailed risk of bias evaluation,see Figure S1 in Supplementary Materials.
3.6.
for each study's detailed risk of bias evaluation,see Figure S1 in Supplementary Materials.
3.6. Meta-analysis
3.6.1. Anxietysymptoms
Between-group effect sizes were small and significant at post-test
(n = 15;g= 0.28, 95% CI [0.16, 0.40]), and follow-up (n = 4;
g= 0.23, 95% CI [0.02, 0.44]) (see also Table 2 andFigure 3A). Het-
erogeneity was medium at post- test (I
2= 35%, 95% CI [0, 78]) and
absent at follow-up (I2= 0%, 95% CI [0, 0]). Excluding one outlier
slightly reduced effects at
and
absent at follow-up (I2= 0%, 95% CI [0, 0]). Excluding one outlier
slightly reduced effects at post-test (n = 14; g= 0.23, 95% CI [0.13,
0.32]), as well as heterogeneity (I2= 0%, 95% CI [0, 23]). Sensitivity
analysis indicated comparable effects for studies using waitlist controls
(n = 10;g= 0.31, 95% CI [0.17, 0.46], I2= 48%, 95% CI [0, 99]) and
when only PP analyses (n = 8; g= 0.23, 95% CI [0.10, 0.37], I2= 0%,
95% CI [0, 43]) were considered. Effects were not significant when
95% CI [0.10, 0.37], I2= 0%,
95% CI [0, 43]) were considered. Effects were not significant when a
mindfulness app was compared to an active psychological treatment
(n = 4;g= 0.26, 95% CI [-0.00, 0.52], I2= 00 %; 95% CI [0, 18]). The
analysis restricted to studies where there was no contact betweenparticipants and researchers yielded slightly higher ES with high het-
erogeneity (n = 6; g= 0.32, 95% CI [0.12, 0.54], I
2= 67%, 95% CI
[20, 85]). However, slightly lower ES was found for studies
95% CI [0.12, 0.54], I
2= 67%, 95% CI
[20, 85]). However, slightly lower ES was found for studies usingHeadspace (n = 6; g= 0.21, 95% CI [0.06, 0.35], I
2= 0%, 95% CI [0,
75]). Sensitivity analyses excluding studies with total RoB scores of 4 orlower led to similar estimations (n = 6; g= 0.40, 95% CI [0.20, 0.60],
I
2= 38 %, 95% CI [0, 74]).
3.6.2. Depressivesymptoms
Between-group effect sizes were significant at post-test (n = 15;
g= 0.33, 95% CI [0.24, 0.43]) (Figure 3B). Effects were not
were significant at post-test (n = 15;
g= 0.33, 95% CI [0.24, 0.43]) (Figure 3B). Effects were not maintainedTable 1 (continued)
Smith et al. (2020) 215 46 33.2 General population Spire Waitlist 4 weeks 4 weeks 1 2.6 Stress, anxiety, PA,
NAPP
vanEmmerik et al. (2018) 377 156 44.7 General population VGZ Coach Waitlist 8 weeks 12 weeks 7 - distres, QOL ITT, PP
Walsh et al. (2019) 108 23 20 Students Wildflowers 2048 app 3 weeks - 7 20.7 stress, PWB PP
Yang et al. (2018) 88 7 25.1 Student Headspace
Wildflowers 2048 app 3 weeks - 7 20.7 stress, PWB PP
Yang et al. (2018) 88 7 25.1 Student Headspace Waitlist 4 weeks 4 weeks 7 11.97 WB, stress ITT, PP
Note. * the control conditions were telephone-based mindfulness training and web-based education about illness; WB well-being, PWB psychological well-being; PA positive affect, NA negative affect, SWL satisfaction
with life, QOL quality of life, PP per-protocol analysis, ITT intent-to-treat analysis; anxiety and depression were measured as
PP per-protocol analysis, ITT intent-to-treat analysis; anxiety and depression were measured as symptoms.É.Gál,etal. Journal of Affective Disorders 279 (2021) 131–142
136 at follow-up (n = 3; g= 0.10, 95% CI [-0.18, 0.38]). Heterogeneity
was zero but with large confidence intervals at post- test (I2= 0%, 95%
CI [0, 83]) and follow-up (I2= 0%, 95% CI [0, 51]). Sensitivity ana-
lyses indicated comparable effects for studies using waitlist controls
(n = 8;g= 0.35, 95% CI [0.24, 0.47], I2= 9%, 95%
effects for studies using waitlist controls
(n = 8;g= 0.35, 95% CI [0.24, 0.47], I2= 9%, 95% CI [0, 0]) or
active psychological treatments as comparators (n = 5; g= 0.28, 95%
CI [0.09, 0.48], I2= 00 %; 95% CI [0, 92]), and when only PP analyses
(n = 10;g= 0.34, 95% CI [0.22, 0.46], I2= 0%, 95% CI [0, 60]) and
studies using Headspace (n = 8; g= 0.36, 95% CI [0.23, 0.49],
I2= 0%, 95% CI [20, 85]) were considered. The analysis restricted to
studies with no contact between participants and
85]) were considered. The analysis restricted to
studies with no contact between participants and researchers also
yielded unchanged effect sizes (n = 6; g= 0.33, 95% CI [0.21, 0.46],
I2= 0%, 95% CI [0, 85]). Sensitivity analyses excluding studies with
total RoB scores of 4 or lower led to similar estimations (n = 6;
g= 0.36, 95% CI [0.20, 0.53], I2= 0 %, 95% CI [0, 98]).
3.6.3. Perceivedstress
Between-group were significant at post-test at post-test (n = 15;
g= 0.46, 95% CI [0.24, 0.68]) with
were significant at post-test at post-test (n = 15;
g= 0.46, 95% CI [0.24, 0.68]) with high heterogeneity (I2= 68%,
95% CI [48, 80]) (Figure S4 in the Supplementary Materials). Excluding
one outlier considerably reduced the effects at post-test (n = 14;
g= 0.32, 95% CI [0.21, 0.44]), and well as heterogeneity (I2= 0%,
95% CI [0, 70]). Results indicate that these effects were maintained atfollow-up (n = 5; g= 0.35, 95% CI [0.17, 0.55], I
2= 0%, 95% CI [0,
14]). Sensitivity analyses indicated
(n = 5; g= 0.35, 95% CI [0.17, 0.55], I
2= 0%, 95% CI [0,
14]). Sensitivity analyses indicated higher effect sizes for comparisonsusing waitlist controls (n = 8; g= 0.62, 95% CI [0.24, 1.01], I
2= 80%,
95% CI [63, 89]) and for studies with no contact between participantsand researchers (n = 8; g= 0.53, 95% CI [0.16, 0.89], I
2= 84%, 95%
CI [73, 92]). However, when one outlier was excluded these effectswere considerably reduced both in the case of studies with waitlist
controls (n = 7; g= 0.38,
effectswere considerably reduced both in the case of studies with waitlist
controls (n = 7; g= 0.38, 95% CI [0.22, 0.54], I
2= 0%, 95% CI [0,
78]) and with no contact between researchers and participants (n = 7;g= 0.29, 95% CI [0.14, 0.43], I2= 0%, 95% CI [0, 0]). Comparisons
with active psychological treatment showed similar estimations to the
main analysis for app-delivered mindfulness interventions (n = 3;
g= 0.34, 95% CI [0.02, 0.68], I2= 00 %; 95% CI [0, 87]), while
slightly lower ES was
(n = 3;
g= 0.34, 95% CI [0.02, 0.68], I2= 00 %; 95% CI [0, 87]), while
slightly lower ES was found for studies using Headspace when the sameoutlier as in the main analysis was excluded (n = 5; g= 0.24, 95% CI
[0.05, 0.44], I
2= 0%, 95% CI [0, 80]). Only three studies had a RoB
score higher than four including an outlier, a sensitivity analysis was
not carried out.
3.6.4. Otherwell-beingindicators
Due to the limited number of available studies, only the mean effect
size was calculated separately
to the limited number of available studies, only the mean effect
size was calculated separately for each outcome and no sensitivity
analyses were carried out (for the different well-being outcomes, except
general well-being and quality of life, figures are presented in
Supplementary Materials; Figures S2 – S8). Results revealed significant
small to medium effect sizes in the case of burnout (n = 3; g= 0.54,
95% CI [0.36, 0.74], I2= 0%, 95% CI [0, 96]), life satisfaction (n = 4;
g= 0.41, 95% CI
3; g= 0.54,
95% CI [0.36, 0.74], I2= 0%, 95% CI [0, 96]), life satisfaction (n = 4;
g= 0.41, 95% CI [0.24, 0.57], I2= 0%, 95% CI [0, 84]), quality of life
(n = 5;g= 0.36, 95% CI [0.11, 0.60], I2= 39%, 95% CI [1, 53])
(Figure 4B), psychological well-being (n = 5; g= 0.29, 95% CI [0.14,
0.45],I2= 0%, 95% CI [0, 61]) small effects sizes were obtained in the
case of positive (n = 5; g= 0.26, 95% CI [0.08, 0.44], I2= 0%, 95% CI
[0, 63]) and negative emotions (n = 5; g= 0.21, 95% CI [0.03, 0.39],
I2=
0.44], I2= 0%, 95% CI
[0, 63]) and negative emotions (n = 5; g= 0.21, 95% CI [0.03, 0.39],
I2= 0%, 95% CI [0, 46]). In contrast, app-delivered mindfulness in-
terventions showed no benefits in reducing distress (n = 6; g= 0.10,
95% CI [-0.02, 0.22], I2= 0%, 95% CI [0, 88]) and improving general
well-being (n = 5; g= 0.14, 95% CI [-0.02, 0.29], I2= 14%, 95% CI
[0, 82]) (Figure 4A). However, if only studies with waitlist or attention
controls were considered app-delivered mindfulness interventions
studies with waitlist or attention
controls were considered app-delivered mindfulness interventions seem
to have small to medium effects on improving well-being (n = 4;
g= 0.31, 95% CI [0.05, 0.56], I2= 0%, 95% CI [0, 85]).
Figure 2. General risk of bias: review authors’ judgements about each risk of bias item presented as percentages across all included studies
Table 2
App-based mindfulness interventions compared to control conditions
Variable N g(95% CI) I2(95% CI) Predictive interval 95%
interventions compared to control conditions
Variable N g(95% CI) I2(95% CI) Predictive interval 95% CI
Post-test
Anxiety 15 0.28 (0.16-0.40) 35 (0-78) -0.03 to 0.59
Outlier excluded 14 0.23 (0.13-0.32) 0 (0-23) 0.13 to 0.33
Depression 15 0.33 (0.24-0.43) 0 (0-0) 0.23 to 0.49
Stress 15 0.46 (0.24-0.68) 68 (48-80) -0.33 to 1.25
Outlier excluded 14 0.32 (0.21-0.44) 0 (0-70) 0.18 to 0.45
General well-being 5 0.14 (-0.02-0.29) 0 (0-82) -0.23 to 0.85
Psychological well-being 5 0.29 (0.14-0.45) 0
well-being 5 0.14 (-0.02-0.29) 0 (0-82) -0.23 to 0.85
Psychological well-being 5 0.29 (0.14-0.45) 0 (0-61) 0.04 to 0.53
Life satisfaction 4 0.41 (0.24-0.57) 0 (0-84) 0.02 to 0.77
Quality of life 5 0.36 (0.11-0.60) 39 (1-53) -0.23 to 0.95
Positive affect 5 0.26 (0.08-0.44) 0 (0-63) -0.03 to 0.55
Negative affect 5 0.21 (0.03-0.39) 0 (0-46) -0.08 to 0.50
Distress 6 0.10 (-0.02- 0.22) 11 (0-82) -0.13 to 0.31
Burnout 3 0.54 (0.36-0.74) 0 (0-96) -0.69 to 1.77
Follow-up
Quality of life 3 0.31 (0.00 -
to 0.31
Burnout 3 0.54 (0.36-0.74) 0 (0-96) -0.69 to 1.77
Follow-up
Quality of life 3 0.31 (0.00 - 0.63) 20 (0-97) -2.12 to 2.74
Anxiety 4 0.23 (0.02-0.44) 0 (0-0) -0.23 to 0.69
Depression 3 0.10 (-0.18-0.38) 0 (0-51) -1.71 to 1.91
Stress 5 0.36 (0.17-0.55) 0 (0-14) 0.05 to 0.66
Note. N, number of studies; g, Hedges’gusing random effects model; 95% CI, 95% confidence interval.É.Gál,etal. Journal of Affective Disorders 279 (2021) 131–142
137 3.7. Smallstudyeffects
The funnel plot appeared to be
of Affective Disorders 279 (2021) 131–142
137 3.7. Smallstudyeffects
The funnel plot appeared to be asymmetrical (see Figure S9 in
Supplementary Materials) for anxiety symptoms. However, Egger's test
was not significant (intercept = -0.79, 95% CI [-2.42, 0.84]). For de-
pressive symptoms neither the funnel plot (Figure S10 in
Supplementary Materials), nor Egger's test suggested publication bias
(intercept = -0.04, 95% CI [-0.88, 0.79]). For perceived stress, the
funnel plot was asymmetrical due
= -0.04, 95% CI [-0.88, 0.79]). For perceived stress, the
funnel plot was asymmetrical due to an outlier (Figure S11 in
Supplementary Materials), but Egger's test was not significant (inter-
cept = 1.61, 95% [CI -1.10, 4.77). All the outcomes had less than 10
studies and small study effects were not assessed.
4. Discussion
Mindfulness meditation apps are becoming increasingly popular as
tools to improve well-being and mental health among the general po-
pulation (Crandall et al., 2019). Thus,
improve well-being and mental health among the general po-
pulation (Crandall et al., 2019). Thus, assessing their effectiveness is
crucial. The present meta-analysis included 34 randomized trials eval-
uating the effectiveness of an app-delivered mindfulness interventionon a wide range of mental-health and well-being outcomes.
Results indicated significant small or medium effects of mindfulness
apps compared to control conditions for perceived stress, symptoms of
depression and anxiety, life
compared to control conditions for perceived stress, symptoms of
depression and anxiety, life satisfaction, quality of life, burnout, psy-
chological well-being and positive and negative affect. Heterogeneity
was generally low, though often with large confidence intervals. Effects
maintained at follow-up for anxiety symptoms, stress and quality of life,
but not for depressive symptoms. Nonetheless, owing to the small
number of studies reporting follow-up assessments, conclusion about
the
owing to the small
number of studies reporting follow-up assessments, conclusion about
the long-term utility of mindfulness meditation apps cannot be drawn.
Although, the obtained effects sizes are close to the tentative cut-off
point (0.24) for clinically relevant effects proposed by Cuijpers et al.,
(2014), prediction intervals of the interventions’ effect generally in-cluded zero suggesting that future studies could also yield non-sig-
nificant effects. There was no evidence of small study
that future studies could also yield non-sig-
nificant effects. There was no evidence of small study effects in the case
of anxiety, depression and stress.
Effects were comparable in sensitivity analyses restricted to intent-
to-treat or per-protocol findings and for studies using Headspace as the
intervention, but reduced in studies where participants had no contact
with researchers. Studies using waitlist controls resulted in slightly
higher effect sizes (a 0.02-0.05 increase in SMD) across
waitlist controls resulted in slightly
higher effect sizes (a 0.02-0.05 increase in SMD) across all outcomes,
adding to the evidence that waitlist comparisons overestimate effects
(Cristea, 2019; Firth et al., 2017a, 2017b). Comparisons restricted to
trials using other active psychological treatments as controls resulted in
slightly lower effects (with a 0.02-0.05 decrease in SMD) compared to
the main analysis for perceived stress and depression, and non-sig-
nificant ESs for anxiety. However,
main analysis for perceived stress and depression, and non-sig-
nificant ESs for anxiety. However, these analyses are based on a small
number of studies with active control conditions and results could be
unreliable.
Our findings confirm those of previous meta-analyses, which also
found small to moderate effect sizes for online mindfulness interven-
tions in improving mental health (g = 0.23, 95% CI [0.09, 0.38])
(Spijkerman et al., 2016) and reducing perceived stress (g = -0.43, 95%
CI [-0.20,
CI [0.09, 0.38])
(Spijkerman et al., 2016) and reducing perceived stress (g = -0.43, 95%
CI [-0.20, -0.66]) (Jaywardene et al., 2017). Similar effects were found
in the case of other (i.e., non-mindfulness) app-delivered interventions
in decreasing the symptoms of anxiety (g = 0.32, 95% CI [0.17- 0.48])
and depression (g = 0.38, 95% CI [0.24- 0.52]) (Firth et al., 2017a,
2017b). Key differences between the present meta-analysis and pre-
vious works relate to the type of app investigated
between the present meta-analysis and pre-
vious works relate to the type of app investigated (mindfulness apps
exclusively vs. all types of apps), delivery method (smartphone apps vs
online) and outcomes (mental health and well-being outcomes vs.
mental health, stress, depression or anxiety only). Our results indicate
that the effects of app-based mindfulness interventions depend on the
type of control condition. Previous meta-analyses have also evidenced
similar patterns when comparing
of control condition. Previous meta-analyses have also evidenced
similar patterns when comparing app-based interventions with active
control conditions (Firth et al., 2017a, 2017b). Similarly, though
Bamber & Morpeth (2018) found large effect sizes when comparing
MBIs to no-treatment controls, small to moderate effects were reported
in another meta-analysis that included studies with active control
conditions (Zoogman et al., 2015).
Non- adherence is a common issue in online psychological
control
conditions (Zoogman et al., 2015).
Non- adherence is a common issue in online psychological inter-
ventions (Linardon & Fuller- Tyszkiewics, 2020), also reflected by our
findings showing that participants completed on average 43% of the
mindfulness meditation sessions, with rates of session completion
varying between 24- 100%. Similarly, Spijkerman et al. (2016) found
that adherence ranged from 39% to 92% in studies on mindfulness-based online interventions. Low user engagement is
ranged from 39% to 92% in studies on mindfulness-based online interventions. Low user engagement is consistently re-
ported in other mental health app studies as well (Firth et al., 2017b).
Furthermore, participants’ motivation to engage in app-use might be
especially low in the absence of severe problems or diagnosed condi-
tions (Jaywardene et al., 2016). Adherence appears to impact the ef-
fectiveness of the interventions, especially for mindfulness, as regular
practice is viewed as key for
of the interventions, especially for mindfulness, as regular
practice is viewed as key for the development of mindfulness skills
(Carmody & Baer, 2008).
Attrition rate, the proportion of participants dropping out before
post-test, was 31% overall, but it was considerably influenced by one
Figure3. Forest plot of standardized mean differences for symptoms of anxiety
(A) and depression (B)É.Gál,etal. Journal of Affective Disorders 279 (2021) 131–142
138 large trial (Mak et al., 2018), in which 547
Journal of Affective Disorders 279 (2021) 131–142
138 large trial (Mak et al., 2018), in which 547 out of 2,283 participants
completed the intervention (23%). The rate is similar to the one (42%)
reported by a meta-analysis examining attrition in smartphone-deliv-
ered interventions (Linardon & Fuller- Tyszkiewics, 2020). Nonetheless,
owing to considerable attrition, estimates of effectiveness might be
biased. Given the pragmatic nature of the trials, where researchers had
no control over
might be
biased. Given the pragmatic nature of the trials, where researchers had
no control over participant engagement, it is likely that adherent par-
ticipants were more motivated to complete the intervention, possibly
because they were also experiencing benefits. To account for the biasing
effects of drop-out, we used intent-to-treat data, when available. In a
meta-analysis on attrition rates in smartphone-delivered intervention
studies Linardon and Fuller- Tyszkiewics (2020) found that
in smartphone-delivered intervention
studies Linardon and Fuller- Tyszkiewics (2020) found that reminding
participants to engage in app use, offering monetary incentives or in-
cluding at least one in-person contact with the researchers significantly
reduced attrition. Crandall et al. (2019) propose that creating more
favorable subjective norms regarding mindfulness meditation andincreasing intentions by emphasizing attitudes and perceived beha-vioral control could be potential methods for
intentions by emphasizing attitudes and perceived beha-vioral control could be potential methods for increasing mindfulness
app engagement.
The prevalence of mental health problems is rising, however, in the
same time the accessibility of evidence-based treatments is limited, andonly a small portion of those in need receive care (Bijl et al., 2003).
According to the World Health Organization mental health promotion
by building up personal strengths, tackling risk factors and improving
the
mental health promotion
by building up personal strengths, tackling risk factors and improving
the quality of life has an important role in mental illness prevention
(Mak et al., 2018). Though, for most outcomes, findings were based on
a limited number of trials, our findings offer a promising signal for the
benefit of mindfulness apps for symptoms of anxiety and depression,
perceived stress, life satisfaction, psychological well-being, burnout,
quality of life, positive and negative emotions.
satisfaction, psychological well-being, burnout,
quality of life, positive and negative emotions. Smartphone interven-
tions could serve as low-cost, scalable and easily accessible tools which
could empower individuals to manage their own mental health
Figure 4. Forest plot of standardized mean differences for general well-being (A) and quality of life (B)É.Gál,etal. Journal of Affective Disorders 279 (2021) 131–142
139 (Carissoli et al., 2015), however, when facing mental health problems
other
279 (2021) 131–142
139 (Carissoli et al., 2015), however, when facing mental health problems
other approaches might be more beneficial.
5. Limitations
The present meta-analysis has several limitations. Comparisons for
some of the well-being and mental health outcomes (i.e., life satisfac-
tion, burnout, general and psychological well-being, quality of life,
positive and negative emotions) and comparisons at follow-up, or with
active control conditions, were based on a small number of
and comparisons at follow-up, or with
active control conditions, were based on a small number of studies,
which might make estimations unreliable. Estimations for comparisons
with active control conditions were heavily influenced by a single trial,
which might question reliability. Furthermore, almost half of the in-
cluded studies used Headspace as the mindfulness intervention, thus,
limiting the generalizability of the conclusions. However, sensitivityanalysis indicated that effects sizes for
generalizability of the conclusions. However, sensitivityanalysis indicated that effects sizes for studies using Headspace ap-
proximate the effect found in the main analysis. Non-adherence was
high among the included studies and as Baumel et al. (2019) suggested,
the trial setting, especially the proactive recruitment of users, has
considerable impact on user engagement in e-mental health programs.
The authors showed that the median program usage in trials was four
times higher than real-world
authors showed that the median program usage in trials was four
times higher than real-world usage. Hence, the real-world general-
izability of our findings might be further constrained, though, most of
the included trials were pragmatic ones where researchers did not in-
fluence participant engagement.
Few included studies assessed the intervention's effect on mind-
fulness skills, making it impossible to ascertain if observed effects are
due to changes in the purported mechanism of change
impossible to ascertain if observed effects are
due to changes in the purported mechanism of change (i.e., mindfulness
skills) or to other non-specific components or expectancies. Participant
adherence (i.e., average number of completed sessions), as well attri-
tion are ubiquitous problems for unguided app- based interventions
(Linardon & Fuller- Tyszkiewics, 2020), and could have also influenced
our findings. Risk of bias might have also biased estimates. Most trials
did not report sufficient
findings. Risk of bias might have also biased estimates. Most trials
did not report sufficient information for assessing potential bias due to
randomization or allocation concealment. One third of the studies did
not report ITT analyses, with some excluding participants from the
analysis if their engagement was not adequate. While this choice can be
justified, in the presence of high attrition rates, it raises questions about
the effectiveness of the intervention, which might only bring benefits
it raises questions about
the effectiveness of the intervention, which might only bring benefits to
a select group of participants who stayed engaged, possibly because
they were experiencing benefits. Yet for app-based interventions to be
scalable, we need to be able to gauge whether there are benefits for the
entire pool of users, not just a selected sample.
6. Conclusions
Although tentatively, the findings of the present meta-analysis
suggest that mindfulness meditation apps are promising
the findings of the present meta-analysis
suggest that mindfulness meditation apps are promising self-manage-
ment tools for improving mental health and well-being. Nonetheless,
due to small number of studies conclusions regarding their long-term
utility cannot be drawn. They are easily accessible, scalable and, if
proven cost-effective, could constitute a feasible alternative to promote
mental health and enhance well-being at a large scale.
Funding
This research did not receive any specific
health and enhance well-being at a large scale.
Funding
This research did not receive any specific grant from funding
agencies in the public, commercial, or not-for-profit sectors.
CRediT authorship contribution statement
Éva Gál: Conceptualization, Methodology, Writing - original draft.
Simona Ștefan: Methodology, Writing - review & editing. Ioana A.
Cristea: Methodology, Writing - review & editing.Declaration of competing interest
The authors have no conflict of interest to
- review & editing.Declaration of competing interest
The authors have no conflict of interest to declare.
Acknowledgements
The authors thank Liviu-Andrei Fodor, Babes-Bolyai University,
Romania for support with the figures.
Supplementary materials
Supplementary material associated with this article can be found, in
the online version, at doi:10.1016/j.jad.2020.09.134.
References
Abbott, D. (2018). Evaluating a smartphone mindfulness intervention's effectiveness at
reducing anxiety and worry.
Evaluating a smartphone mindfulness intervention's effectiveness at
reducing anxiety and worry. (Unpublished Doctoral Dissertation). University of
Central Oklahoma, Edmond, Oklahoma.
Bamber, M.D., Morpeth, E., 2018. Effects of mindfulness meditation on college student
anxiety: A meta-analysis. Mindfulness 10, 203–214. https://doi.org/10.1007/
s12671-018-0965-5.
Baumel, A., Edan, S., Kane, J.M., 2019. Is there a trial bias impacting user engagement
with unguided e-mental health interventions? A
2019. Is there a trial bias impacting user engagement
with unguided e-mental health interventions? A systematic comparison of published
reports and real-world usage of the same programs. Translational Behavioral
Medicine 9, 1020–1033. https://doi.org/10.1093/tbm/ibz147.
Bhayee, S., Tomaszewski, P., Lee, D.H., Moffat, G., Pino, L., Moreno, S., Farb, N.A.S.,
2016. Attentional and affective consequences of technology supported mindfulness
training: a randomized, active control, efficacy trial. BMC
of technology supported mindfulness
training: a randomized, active control, efficacy trial. BMC Psychology 4, 60. https://
doi.org/10.1186/s40359-016-0168-6.
Bijl, R.V., de Graaf, R., Hiripi, E., Kessler, R.C., Kohn, R., Offord, D.R., Wittchen, H.U.,
2003. The prevalence of treated and untreated mental disorders in five countries.
Health Affairs 22, 122–133. https://doi.org/10.1377/hlthaff.22.3.122.
Borjalilu, S., Mazaheri, M.A., Talebpour, A., 2019. Effectiveness of mindfulness-based
stress
S., Mazaheri, M.A., Talebpour, A., 2019. Effectiveness of mindfulness-based
stress management in the mental health of Iranian university students: a comparison
of blended therapy, face-to-face sessions, and mHealth app (Aramgar). Iranian
Journal of Behavioral Sciences 13, e84726. https://doi.org/10.5812/ijpbs.84726.
Borenstein, M., Hedges, L.V., Higgins, J.P., Rothstein, H.R., 2011. Introduction to meta-
analysis. John Wiley & Sons.
Bostock, S., Crosswell, A.D., Prather, A.A., Steptoe, A., 2019.
meta-
analysis. John Wiley & Sons.
Bostock, S., Crosswell, A.D., Prather, A.A., Steptoe, A., 2019. Mindfulness on-the-go:
Effects of a mindfulness meditation app on work stress and well-being. Journal ofOccupational Health Psychology 24, 127–138. https://doi.org/10.1037/
ocp0000118.
Carissoli, C., Villani, D., Riva, G., 2015. Does a meditation protocol supported by a mobile
application help people reduce stress? Suggestions from a controlled pragmatic trial.
Cyberpsychology, Behavior, and Social
reduce stress? Suggestions from a controlled pragmatic trial.
Cyberpsychology, Behavior, and Social Networking 18, 46–53. https://doi.org/10.
1089/cyber.2014.0062.
Carissoli, C., Villania, D., Gasparria, D., Rivaa, G., 2017. Enhancing psychological well-
being of women approaching the childbirth: a controlled study with a mobile ap-plication. Annual Review of Cybertherapy and Telemedicine 45, 45–50.
Carmody, J., Baer, R.A., 2008. Relationships between mindfulness practice and levels
45, 45–50.
Carmody, J., Baer, R.A., 2008. Relationships between mindfulness practice and levels of
mindfulness, medical and psychological symptoms and well-being in a mindfulness-based stress reduction program. Journal of Behavioral Medicine 31, 23–33. https://
doi.org/10.1007/s10865-007-9130-7.
Cavanagh, K., Strauss, C., Forder, L., Jones, F., 2014. Can mindfulness and acceptance be
learnt by self-help?: A systematic review and meta-analysis of mindfulness and ac-
ceptance-based self-help
by self-help?: A systematic review and meta-analysis of mindfulness and ac-
ceptance-based self-help interventions. Clinical Psychology Review 34, 118–129.
https://doi.org/10.1016/j.cpr.2014.01.001.
Champion, L., Economides, M., Chandler, C., 2018. The efficacy of a brief app-based
mindfulness intervention on psychosocial outcomes in healthy adults: A pilot ran-
domised controlled trial. PloS One 13, e0209482. https://doi.org/10.1371/journal.
pone.0209482.
Clarke, T.C., Black, L.I., Stussman,
13, e0209482. https://doi.org/10.1371/journal.
pone.0209482.
Clarke, T.C., Black, L.I., Stussman, B.J., Barnes, P.M., Nahin, R.L., 2015. Trends in the use
of complementary health approaches among adults: United States, 2002–2012.
National Health Statistics Reports.
Cohen, J., 2013. Statistical power analysis for the behavioral sciences. Routledge.Compen, F., Schellekens, M., Carlson, L., van der Lee, M., Speckens, A., 2018. Face-to-face
and internet-based mindfulness-based cognitive therapy
der Lee, M., Speckens, A., 2018. Face-to-face
and internet-based mindfulness-based cognitive therapy compared with treatment as
usual in reducing psychological distress in patients with cancer: A multicenter ran-
domized controlled trial. Journal of Clinical Oncology 36, 2413–2421. https://doi.
org/10.1200/jco.2017.76.5669.
Coulon, S.M., Monroe, C.M., West, D.S., 2016. A systematic, multi-domain review of
mobile smartphone apps for evidence-based stress management. American journal of
preventive
of
mobile smartphone apps for evidence-based stress management. American journal of
preventive medicine 51, 95–105. https://doi.org/10.1016/j.amepre.2016.01.026.
Cox, C.E., Hough, C.L., Jones, D.M., Ungar, A., Reagan, W., Key, M.D., Porter, L.S., 2019.
Effects of mindfulness training programs delivered by a self-directed mobile app and
by telephone compared with an education program for survivors of critical illness: a
pilot randomised clinical trial. Thorax 74, 33–42.
program for survivors of critical illness: a
pilot randomised clinical trial. Thorax 74, 33–42. https://doi.org/10.1136/thoraxjnl-
2017-211264.
Crandall, A., Cheung, A., Young, A., Hooper, A.P., 2019. Theory-Based Predictors ofÉ.Gál,etal.
Journal of Affective Disorders 279 (2021) 131–142
140 Mindfulness Meditation Mobile App Usage: A Survey and Cohort Study. JMIR
mHealth and uHealth 7, e10794. https://doi.org/10.2196/10794.
Cristea, I.A., 2019. The waiting list in an inadequate benchmark for
https://doi.org/10.2196/10794.
Cristea, I.A., 2019. The waiting list in an inadequate benchmark for estimating the ef-
fectiveness of psychotherapy for depression. Epidemiology and Psychiatric Sciences
28, 278–279. https://doi.org/10.1017/S2045796018000665.
Cuijpers, P., Turner, E.H., Koole, S.L., van Dijke, A., Smit, F., 2014. What is the threshold
for a clinically relevant effect? The case of major depressive disorders. Depression
and Anxiety 31, 374–378.
relevant effect? The case of major depressive disorders. Depression
and Anxiety 31, 374–378. https://doi.org/10.1002/da.22249.
Cuijpers, P., 2016. Meta-analyses in mental health research. A practical guide.
Amsterdam, the Netherlands: Pim Cuijpers Uitgeverij.
Cuijpers, P., Weitz, E., Cristea, I.A., Twisk, J., 2016. Pre- post effect sizes should be
avoided in meta- analyses. Epidemiology and Psychiatric Sciences 1–5. https://doi.
org/10.1017/s2045796016000809.
Diener, E., 2000. Subjective
Psychiatric Sciences 1–5. https://doi.
org/10.1017/s2045796016000809.
Diener, E., 2000. Subjective well-being: the science of happiness and a proposal for a
national index. American Psychologist 55, 34–43. https://doi.org/10.1037/0003-
066x.55.1.34.
Donovan, E., Rodgers F., R., Cousineau M., T., McGowen M., K., Luk, S., Yates, K., Franko
L., D., 2016. Brief report: Feasability of a mindfulness and self-compassion basedmobile intervention for adolescents. Journal of Adolescence 52, 217–221.
and self-compassion basedmobile intervention for adolescents. Journal of Adolescence 52, 217–221. https://
doi.org/10.1016/j.adolescence.2016.09.009.
Economides, M., Martman, J., Bell, M.J., Sanderson, B., 2018. Improvements in stress,
affect, and irritability following brief use of a mindfulness-based smartphone app: a
randomized controlled trial. Mindfulness 9, 1584–1593. https://doi.org/10.1007/
s12671-018-0905-4.
Egger, M., Davey, S.G., Schneider, M., Minder, C., 1997. Bias in meta-analysis
M., Davey, S.G., Schneider, M., Minder, C., 1997. Bias in meta-analysis detected by
a simple, graphical test. BMJ 315, 629–634. https://doi.org/10.1136/bmj.315.7109.
629. (Clinical Research ed.).
Fairburn, C.G., Patel, V., 2017. The impact of digital technology on psychological treat-
ments and their dissemination. Behavior Research and Therapy 88, 19–25. https://
doi.org/10.1176/appi.focus.16405.
Firth, J., Torous, J., Nicholas, J., Carney, R., Rosenbaum, S., Sarris, J., 2017a. Can
smartphone
J., Torous, J., Nicholas, J., Carney, R., Rosenbaum, S., Sarris, J., 2017a. Can
smartphone mental health interventions reduce symptoms of anxiety? A meta-ana-lysis of randomized controlled trials. Journal of Affective Disorders 218, 15–22.
https://doi.org/10.1016/j.jad.2017.04.046.
Firth, J., Torous, J., Nicholas, J., Carney, R., Pratap, A., Rosenbaum, S., Sarris, J., 2017b.
The efficacy of smartphone‐based mental health interventions for depressive symp-toms: a meta‐analysis of randomized
smartphone‐based mental health interventions for depressive symp-toms: a meta‐analysis of randomized controlled trials. World Psychiatry 16, 287–298.
https://doi.org/10.1002/wps.20472.
Fish T, M, Saul D, A, 2019. The gamification of meditation: a randomized-controlled
study of a prescribed mobile mindfulness meditation application in reducing college
students’ depression. Simulation & Gaming 50 (4), 419–435. https://doi.org/10.
1177/1046878119851821.
Flett, J.A., Hayne, H., Riordan, B.C.,
50 (4), 419–435. https://doi.org/10.
1177/1046878119851821.
Flett, J.A., Hayne, H., Riordan, B.C., Thompson, L.M., Conner, T.S., 2019. Mobile mind-
fulness meditation: a randomized controlled trial of the effect of two popular apps on
mental health. Mindfulness 10, 863–876. https://doi.org/10.1007/s12671-018-
1050-9.
Flett, J.A., M., Conner, T.S., Riordan, B.J., Patterson, T., Hayne, H., 2020. App-based
mindfulness meditation for psychological distress and adjustment to college in in-
coming
App-based
mindfulness meditation for psychological distress and adjustment to college in in-
coming university students: a pragmatic, randomized, waitlist-controlled trial.
Psychology and Health. https://doi.org/10.1080/08870446.2019.1711089.
Forbes, G., Newton, S., Calvete, C., Birch, J., Dodds, J., Steed, L., Rivas, C., Khan, K.,
Rohricht, F., Taylor, S., Kahan, B.C., Ball, E., 2020. MEMPHIS: a smartphone app
using psychological approaches for women with pelvic pain presenting to
MEMPHIS: a smartphone app
using psychological approaches for women with pelvic pain presenting to gynecology
clinics: a randomized feasibility trial. BMJ Open 10, e030164. https://doi.org/10.
1136/bmjopen-2019-030164.
García, I.P., Sánchez, C.M., Espílez, Á.S., García-Magariño, I., Guillén, G.A., García-
Campayo, J., 2017. Development and initial evaluation of a mobile application to
help with mindfulness training and practice. International journal of medical infor-
matics 105, 59–67.
with mindfulness training and practice. International journal of medical infor-
matics 105, 59–67. https://doi.org/10.1016/j.ijmedinf.2017.05.018.
Heeter, C., Lehto, R., Allbritton, M., Day, T., Wiseman, M., 2017. Effects of a technology-
assisted meditation program on healthcare providers’ interoceptive awareness,compassion fatigue, and burnout. Journal of Hospice & Palliative Nursing 19,
314–322. https://doi.org/10.1097/njh.0000000000000349.
Hedges, L.V., Vevea, J.L., 1998. Fixed- and
https://doi.org/10.1097/njh.0000000000000349.
Hedges, L.V., Vevea, J.L., 1998. Fixed- and random-effects models in meta-analysis.
Psychological Methods 3, 486–504. https://doi.org/10.1037/1082-989x.3.4.486.
Higgins, I., & Green, S. (2011). Cochrane handbook for systematic reviews of interven-
tions Version 5.1.0 [updated March 2011].
Huberty, J., Green, J., Glissman, C., Larkey, L., Puiza, M., Lee, C., 2019a. Efficacy of the
mindfulness meditation app “Calm” to reduce stress among college
M., Lee, C., 2019a. Efficacy of the
mindfulness meditation app “Calm” to reduce stress among college students: rando-mized controlled trial. JMR mHealth and uHealth 7, e14273. https://doi.org/10.
2196/14273.
Howells, A., Ivtzan, I., Eiroa-Orosa, F.J., 2016. Putting the ‘app’ in happiness: a rando-
mized controlled trial of a smartphone-based mindfulness intervention to enhance
wellbeing. Journal of Happiness Studies 17, 163–185.
Huberty, J., Eckert, R., Larkey, L., Kurka, J., Jesus, S.R., Yoo,
of Happiness Studies 17, 163–185.
Huberty, J., Eckert, R., Larkey, L., Kurka, J., Jesus, S.R., Yoo, W., Mesa, R., 2019.
Smartphone-based meditation for myeloproliferative neoplasm patients: feasibility
study to inform future trials. JMIR Formative Research 3, e126621. https://doi.org/
10.2196/12662.
IntHout, J., Ioannidis, J.P.A., Rovers, M.M., Goeman, J.J., 2016. Plea for routinely pre-
senting prediction intervals in meta-analysis. BMJ Open 6, e010247.
2016. Plea for routinely pre-
senting prediction intervals in meta-analysis. BMJ Open 6, e010247. https://doi.org/
10.1136/bmjopen-2015-010247.
Jaywardene, W.P., Lohrmann, D.K., Erbe, R.G., Torabi, M.R., 2017. Effects of preventive
online mindfulness interventions on stress and mindfulness: A meta- analysis ofrandomized controlled trials. Preventive Medicine Reports 5, 150–159. https://doi.
org/10.1016/j.pmedr.2016.11.013.
Kabat-Zinn, J., 2003. Mindfulness-based interventions in context: past,
J., 2003. Mindfulness-based interventions in context: past, present, andfuture. Clinical Psychology 10 (2), 144–156. https://doi.org/10.1093/clipsy/
bpg016.
Kahneman, D., Diener, E., Schwarz, N. (Eds.), 1999. Well-being: Foundations of hedonic
psychology. Sage Foundation, Russell.
Keng, S.L., Smoski, M.J., Robins, C.J., 2011. Effects of mindfulness on psychological
health: A review of empirical studies. Clinical Psychology Review 31, 1041–1056.https://doi.org/10.1016/j.cpr.2011.04.006.
Krusche,
Clinical Psychology Review 31, 1041–1056.https://doi.org/10.1016/j.cpr.2011.04.006.
Krusche, A., Cyhlarova, E., King, S., Williams, J.M.G., 2012. Mindfulness online: a pre-
liminary evaluation of the feasibility of a web-based mindfulness course and theimpact on stress. BMJ Open 2, e000803. https://doi.org/10.1136/bmjopen-2011-
000803.
Kubo, A, Kurtovich, E, McGinnis, M, Aghaee, S, Altschuler, A, Quesenberry, C, Kolevska,
T, Avins, A, 2019. A randomized controlled trial of mHealth mindfulness
A, Quesenberry, C, Kolevska,
T, Avins, A, 2019. A randomized controlled trial of mHealth mindfulness intervention
for cancer patients and informal cancer caregivers: A feasability study within an
integrated health care delivery system. Integrative Cancer Therapies 18, 1–13.
https://doi.org/10.1177/1534735419850634.
Kuyken, W., Warren, F.C., Taylor, R.S., Whalley, B., Crane, C., Bondolfi, G., Segal, Z.,
2016. Efficacy of mindfulness-based cognitive therapy in prevention of depressive
relapse: an
Z.,
2016. Efficacy of mindfulness-based cognitive therapy in prevention of depressive
relapse: an individual patient data meta-analysis from randomized trials. JAMA
psychiatry 73, 565–574. https://doi.org/10.1001/jamapsychiatry.2016.0076.
Lakhan, S.E., Schofield, K.L., 2013. Mindfulness-based therapies in the treatment of so-
matization disorders: a systematic review and meta-analysis. PloS One 8, e71834.
https://doi.org/10.1371/journal.pone.0071834.
Lanz, J., Fritson, K., Hoffert, K., Carillo,
e71834.
https://doi.org/10.1371/journal.pone.0071834.
Lanz, J., Fritson, K., Hoffert, K., Carillo, K.C., 2019. Reducing burnout through a mindful
meditation app: a randomized controlled trial. Journal of Psychology and BehavioralSciences 7, 66–73. https://doi.org/10.15640/jpbs.v7n2a1.
Lee, R.A., Jung, M.E., 2018. Evaluation of an mHealth App (DeStressify) on University
Students’ Mental Health: Pilot Trial. JMIR Mental Health 5, e2. https://doi.org/10.
2196/mental.8324.
Leigh, S., Flatt, S.,
Pilot Trial. JMIR Mental Health 5, e2. https://doi.org/10.
2196/mental.8324.
Leigh, S., Flatt, S., 2015. App-based psychological interventions: friend or foe? Evidence-
Based Mental Health 18, 97–99. https://doi.org/10.1136/eb-2015-102203.
Lengacher, C.A., Reich, R.R., Ramesar, S., Alinat, C.B., Moscoso, M., Cousin, L.,
Rodriguez, C.S., 2018. Feasibility of the mobile mindfulness‐based stress reduction
for breast cancer (mMBSR (BC)) program for symptom improvement among breast
cancer survivors.
breast cancer (mMBSR (BC)) program for symptom improvement among breast
cancer survivors. Psycho‐Oncology 27, 524–531. https://doi.org/10.1002/pon.4491.
Levin, M., Hicks, E.T., Kraft, J., 2020. Pilot evaluation of the stop, breathe & think
mindfulness app for student clients on a college counseling center waitlist. Journal of
American College Health. https://doi.org/10.1080/07448481.2020.1728281.
Linardon, J., Fuller-Tyszkiewicz, M., 2020. Attrition and adherence in smartphone-de-
livered
J., Fuller-Tyszkiewicz, M., 2020. Attrition and adherence in smartphone-de-
livered interventions for mental health problems: A systematic and meta-analytic
review. Journal of Consulting and Clinical Psychology 88, 1–13. https://doi.org/10.
1037/ccp0000459.
Linardon, J., Cuijpers, P., Carlbring, P., Messer, M., Fuller-Tyszkievicz, M., 2019. The
efficacy of app-supported smartphone interventions for mental health problems: a
meta-analysis of randomized controlled trials. World Psychiatry 18,
for mental health problems: a
meta-analysis of randomized controlled trials. World Psychiatry 18, 325–336.
https://doi.org/10.1002/wps.20673.
Lomas, T., Medina, J.C., Ivtzan, I., Rupprecht, S., Eiroa-Orosa, F.J., 2018. A systematic
review and meta-analysis of the impact of mindfulness-based interventions on the
well-being of healthcare professionals. Mindfulness 10, 1193–1216. https://doi.org/
10.1007/s12671-018-1062-5.
Loree, L., 2018. Mindfulness and cognitive behavior therapy: a comparison of
L., 2018. Mindfulness and cognitive behavior therapy: a comparison of brief app-
based interventions on stress management among foster parents. Northern ArizonaUniversity (Unpublished Doctoral Dissertation).
Mace, C., 2007. Mindfulness and mental health: Therapy, theory and science. Routledge.
Mak, W.W., Tong, A.C., Yip, S.Y., Lui, W.W., Chio, F.H., Chan, A.T., Wong, C.C., 2018.
Efficacy and Moderation of Mobile App–Based Programs for Mindfulness-Based
Training, Self-Compassion Training, and
of Mobile App–Based Programs for Mindfulness-Based
Training, Self-Compassion Training, and Cognitive Behavioral Psychoeducation on
Mental Health: Randomized Controlled Noninferiority Trial. JMIR Mental Health 5,
e60. https://doi.org/10.2196/mental.8597.
Mani, M., Kavanagh, D.J., Hides, L., Stoyanov, S.R., 2015. Review and evaluation of
mindfulness-based iPhone apps. JMIR mHealth and uHealth 3, e82. https://doi.org/
10.2196/mhealth.4328.
Mikolasek, M., Berg, J., Witt, C.M., Barth, J., 2018.
3, e82. https://doi.org/
10.2196/mhealth.4328.
Mikolasek, M., Berg, J., Witt, C.M., Barth, J., 2018. Effectiveness of mindfulness-and
relaxation-based eHealth interventions for patients with medical conditions: a sys-
tematic review and synthesis. International Journal of Behavioral Medicine 25, 1–16.
https://doi.org/10.1007/s12529-017-9679-7.
Moberg, C., Niles, A., Beerman, D., 2019. Guided self-help works: randomized waitlist
controlled trial of Pacifica, a mobile app integrating cognitive
works: randomized waitlist
controlled trial of Pacifica, a mobile app integrating cognitive behavioral therapy and
mindfulness for stress, anxiety and depression. Journal of Medical Internet Research
21, e12556. https://doi.org/10.2196/12556.
Moher, D., Liberati, A., Tetzlaff, J., Altman, D.G., Altman, D., Antes, G., et al., 2009.
Preferred reporting items for systematic reviews and meta-analyses: The prismastatement. PLoS Medicine 6, e1000097.
items for systematic reviews and meta-analyses: The prismastatement. PLoS Medicine 6, e1000097. https://doi.org/10.7326/0003-4819-151-4-
200908180-00135.
Möltner, H., Leve, J., Esch, T., 2018. Burnout Prevention and Mobile Mindfulness:
Evaluation of an App-Based Health Training Program for Employees.Gesundheitswesen (Bundesverband der Arzte des Offentlichen Gesundheitsdienstes)80, 295–300. https://doi.org/10.1055/s-0043-114004.
Muuraiskangas, S., Harjumaa, M., Kaipainen, K., Ermes, M., 2016.
S., Harjumaa, M., Kaipainen, K., Ermes, M., 2016. Process and effects
evaluation of a digital mental health intervention targeted at improving occupational
well-being: lessons from an intervention study with failed adoption. JMIR Mental
Health 3, e13. https://doi.org/10.2196/mental.4465.
Nicholas, J., Larsen, M., Christensen, H., Proudfoot, J., 2015. Mobile apps for bipolar
disorder: a systematic review of features and content quality. Journal of MedicalInternet Research 17, e198.
a systematic review of features and content quality. Journal of MedicalInternet Research 17, e198. https://doi.org/10.2196/jmir.4581.
Nolan, J. (2019). Effectiveness, feasibility and acceptability of a mindfulness basedÉ.Gál,etal.
Journal of Affective Disorders 279 (2021) 131–142
141 mobile application for undergraduate health science students. (Unpublished Doctoral
Dissertation). University of Central Arkansas, Conway, Arkansas.
Pesce, N. L. (2018). This was the hottest app trend of the year.
Central Arkansas, Conway, Arkansas.
Pesce, N. L. (2018). This was the hottest app trend of the year. https://www.
marketwatch.com/story/this-was-the-hottest-app-trend-of-the-year-2018-12-07 (ac-
cessed 19 June 2020).
Noone, C., Hogan, M.J., 2018. A randomized active-controlled trial to examine the effects
of an online mindfulness intervention on executive control, critical thinking and key
thinking dispositions in a university student sample. BMC Psychology 6, 13.
thinking and key
thinking dispositions in a university student sample. BMC Psychology 6, 13. https://
doi.org/10.1186/s40359-018-0226-3.
Plaza, I., Demarzo, M.M.P., Herrera-Mercadal, P., García-Campayo, J., 2013.
Mindfulness-based mobile applications: literature review and analysis of currentfeatures. JMIR mHealth and uHealth 1, e24. https://doi.org/10.2196/mhealth.2733.
Pospos, S., Young, I.T., Downs, N., Iglewicz, A., Depp, C., Chen, J.Y., Zisook, S., 2018.
Web-based tools and mobile
I.T., Downs, N., Iglewicz, A., Depp, C., Chen, J.Y., Zisook, S., 2018.
Web-based tools and mobile applications to mitigate burnout, depression, and sui-cidality among healthcare students and professionals: a systematic review. Academic
Psychiatry 42, 109–120. https://doi.org/10.1007/s40596-017-0868-0.
Reibel, D., McCrown, D., 2019. Mindfulness Based Stress Reduction: theory, practice and
evidence base. In: Ivtzan, I. (Ed.), Handbook of mindfulness-based programmes.
Routlege.
Quinones, C.,
base. In: Ivtzan, I. (Ed.), Handbook of mindfulness-based programmes.
Routlege.
Quinones, C., Griffiths, M.D., 2019. Reducing compulsive internet use and anxiety
symptoms via two brief interventions: a comparison between mindfulness and gra-dual muscle relaxation. Journal of Behavioral Addictions. https://doi.org/10.1556/
2006.8.2019.45.
Robinson, C. M. (2018). Are you in the right Headspace? Using a mindfulness-based
mobile application as a wellbeing intervention in the workplace.
Using a mindfulness-based
mobile application as a wellbeing intervention in the workplace. (Unpublished
Master's Thesis). University of Canterbury.
Rosen, K.D., Paniagua, S.M., Kazanis, W., Jones, S., Potter, J.S., 2018. Quality of life
among women diagnosed with breast Cancer: A randomized waitlist-controlled trial
of commercially available mobile app‐delivered mindfulness training.
Psycho‐Oncology 27, 2023–2030. https://doi.org/10.1002/pon.4764.
Ryff, C.D., Keyes, C.L.M., 1995. The structure
27, 2023–2030. https://doi.org/10.1002/pon.4764.
Ryff, C.D., Keyes, C.L.M., 1995. The structure of psychological well-being revisited.
Journal of Personality and Social Psychology 69, 719–727.
Siembor, B. (2017). Exploring the effectiveness of a mindfulness training app for mana-
ging stress in a university student population: a pilot study. (Unpublished Doctoral
Dissertation). Northeastern University, Boston, Massachusets.
Smith N, E, Santoro, E, Moraveji, N, Susi, M, Crum J, A, 2020.
University, Boston, Massachusets.
Smith N, E, Santoro, E, Moraveji, N, Susi, M, Crum J, A, 2020. Integrating wearables instress management interventions: Promising evidence from a randomized trial.
International Journal of Stress Management 27 (2), 172–182. https://doi.org/10.
1037/str0000137.
Spijkerman, M.P.J., Pots, W.T.M., Bohlmeijer, E.T., 2016. Effectiveness of online mind-
fulness-based interventions in improving mental health: A review and meta-analysisof randomised controlled trials.
interventions in improving mental health: A review and meta-analysisof randomised controlled trials. Clinical Psychology Review 45, 102–114. https://doi.
org/10.1016/j.cpr.2016.03.009.
Sucala, M., Cuijpers, P., Muench, F., Cardoș, R., Soflau, R., Dobrean, A., Achimas-Cadariu,
P., David, D., 2017. Anxiety: There is an app for that. A systematic review of anxiety
apps. Depression and Anxiety. 34, 518–525. https://doi.org/10.1002/da.22654.
Tirch, D., Silberstein, L.R., Kolts, R.L., 2015. Buddhist
518–525. https://doi.org/10.1002/da.22654.
Tirch, D., Silberstein, L.R., Kolts, R.L., 2015. Buddhist psychology and cognitive-beha-
vioral therapy: A clinician's guide.
van Emmerik, A.A., Berings, F., Lancee, J., 2018. Efficacy of a mindfulness-based mobile
application: a randomized waiting-list controlled trial. Mindfulness 9, 187–198.https://doi.org/10.1007/s12671-017-0761-7.
Vøllestad, J., Nielsen, M.B., Nielsen, G.H., 2012. Mindfulness- and acceptance-based in-
terventions for anxiety
Nielsen, M.B., Nielsen, G.H., 2012. Mindfulness- and acceptance-based in-
terventions for anxiety disorders: a systematic review and meta-analysis. The British
Journal of Clinical Psychology 51, 239–260. https://doi.org/10.1111/j.2044-8260.
2011.02024.x.
Wahbeh, H., Oken, B.S., 2016. Internet mindfulness meditation intervention for the
general public: pilot randomized controlled trial. JMIR Mental Health 3, e37. https://
doi.org/10.2196/mental.5900.
Walsh, K.M., Saab, B.J., Farb, N.A., 2019.
Health 3, e37. https://
doi.org/10.2196/mental.5900.
Walsh, K.M., Saab, B.J., Farb, N.A., 2019. Effects of a Mindfulness Meditation App on
Subjective Well-Being: Active Randomized Controlled Trial and Experience Sampling
Study. JMIR Mental Health 6, e10844. https://doi.org/10.2196/10844.
Wen, L., Sweeney, T.E., Welton, L., Trockel, M., Katznelson, L., 2017. Encouraging
mindfulness in medical house staff via smartphone app: A pilot study. Academic
Psychiatry 41, 646–650.
in medical house staff via smartphone app: A pilot study. Academic
Psychiatry 41, 646–650. https://doi.org/10.1007/s40596-017-0768-3.
Yang, E., Schamber, E., Meyer, R.M., Gold, J.I., 2018. Happier healers: Randomized
controlled trial of mobile mindfulness for stress management. The Journal of
Alternative and Complementary Medicine 24, 505–513. https://doi.org/10.1089/
acm.2015.0301.
Zoogman, S., Goldberg, S.B., Hoyt, W.T., Miller, L., 2015. Mindfulness interventions with
youth: A meta-analysis.
Goldberg, S.B., Hoyt, W.T., Miller, L., 2015. Mindfulness interventions with
youth: A meta-analysis. Mindfulness 6, 290–302. https://doi.org/10.1007/s12671-
013-0260-4.É.Gál,etal.
Journal of Affective Disorders 279 (2021) 131–142
142
